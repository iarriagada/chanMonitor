{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a196f1de-aeac-4e51-9f94-a6e8d17d69bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plotting data from GEA\n",
    "## Intro\n",
    "This is an example Jupyter Notebook to show how our hacky EPICS Data Capture and Plotting python scripts can be turned into a Powerful AF (tm) web tool to analyze data.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Disclaimer!:</b> This is not meant to completely replace GEA but to be more of an in-depth follow-up analysis tool.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eddc55-635f-4c94-af58-8dfccddf835d",
   "metadata": {},
   "source": [
    "## The awesome Real Time EPICS data analysis module\n",
    "The developer's purpose with this module was to give the users some flexibility into how to plot and analyze data gathered from our EPICS systems.\n",
    "\n",
    "The first part of the module is the utility that allows the user to get data from GEA or directly from EPICS IOCs. GEA being our engineering archive is an extensive database compiled through times immemorial. However, being able to harvest data from IOCs for a particular test or investigation without having to configure said records in GEA (!!!) is also nice.\n",
    "\n",
    "The main script in this section, found in `./util/` is:\n",
    " - `inPosDataCap.py`\n",
    "\n",
    "The library being used by this script, found in `./lib/` is:\n",
    " - `dataFromGea.py`\n",
    " \n",
    "The second part of the module is the python library that provides the users with tools to manipulate and plot data. In this library the users will find a myriad of methods/functions/utilities to filter/compare/enhance data. However, the killer functionality is the set of classes that allow for plots to be formatted and tiled without having to deal with the all that fun and exciting matplotlib crap (jk, matplotlib is the goat).\n",
    "All goodies are found in the python file in `./lib/`:\n",
    " - `plotEpicsData.py`\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> As a bonus, the module allowed the dev to be a lazy pos that couldn't be bother to develop an actual UI, which would have been way better.\n",
    "</div>\n",
    "\n",
    "### Requirements and installation\n",
    "This tool does not have very complicated requirements to run. The installation is really just cloning the repo from Gitlab.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Futurism Alert!:</b> I'm working on a container that should take care of most of the requirements, possibly more. But don't hold your breath.\n",
    "</div>\n",
    "\n",
    "#### Linux Requirements\n",
    "Your machine (or container) needs the following core packages (as well as all their requirements, of course)\n",
    " - **EPICS >= 3.14** (or if you find a way to run Channel Access without the core epics installation, even better)\n",
    " - **Python >= 3.9** (I couldn't get interactive jupyter plots to work with 3.6)\n",
    " - **PIP3**\n",
    " - **node.js**\n",
    "\n",
    "#### Python module requirements\n",
    "These modules are needed to run the python scripts and functions (all modules for version >= 3.9 will work, install the latest with `pip3`)\n",
    " - **pyepics**\n",
    " - **numpy**\n",
    " - **h5py**\n",
    " - **ipympl**\n",
    " - **jupyterlab**\n",
    "\n",
    "#### Installation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce3872-22ae-4128-8c7f-1eb23ec0eefb",
   "metadata": {},
   "source": [
    "## How to gather data\n",
    "As it was mentioned above, data can be harvested after the fact from GEA or capturing a live data stream by tapping directly into IOCs. Data is gathered using the script `inPosDataCap.py`. All data is saved by default in the `./data/` directory.\n",
    "\n",
    "The utility `inPosDataCap.py` has two modes:\n",
    " - **GEA**: This mode is enabled by the argument `gea`. In its most basic form it **reads an input text file** passed as an argument, which contains a list of EPICS channels. The data is gathered for the **time window specified by the time string input** arguments with format `yymmddTHHMM`. The user also need to specify the **site from which data is being gathered** (input argument `gs` for Gemini South and `gn` for Gemini North). The data is then returned as an __[hdf5](https://www.neonscience.org/resources/learning-hub/tutorials/about-hdf5)__ file with the default prefix `recDataGea-{start_date}`. An example command would go as follow:\n",
    "    ```\n",
    "    $ ./util/inPosDataCap.py gea gs FastTrack-chans.txt 230412T2200 230412T2300\n",
    "    \n",
    " \n",
    "    ```    \n",
    "    This would gather the data from **GEA South** for the channels in `FastTrack-chans.txt` and write it to the file `recDataGea-230412T2200.h5`. The file is saved to `./data`, since no custom dir was specified in the arguments.\n",
    "\n",
    " - **Channel Access**: This mode is enabled by the input argument `ca`. Data is collected live for the list of EPICS channels especified in the **input text file**, for the duration specified by the user (eg. -`hr 3` would set the script to capture data for 3 hours). An example command is shown below\n",
    "    ```\n",
    "    $ ./util/inPosDataCap.py ca BtO-chans.txt -min 45\n",
    "    \n",
    "    \n",
    "    ```\n",
    "    This would set CA monitors to gather data from the channels specified in `BtO-chans.txt` for 45 min after the execution of the command. Once the capture timer is done, the file `recMonCA-{date-of-execution}.h5` would be generated and stored in `./data`, as no user dir was specified.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Dig deeper:</b> There are other options for interacting with this utility. Check <code>inPosDataCap.py gea -h</code> and <code>inPosDataCap.py ca -h</code> for more details.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8c355-edbc-4f16-927c-395f8e9d214e",
   "metadata": {},
   "source": [
    "## How to analyze and plot the data\n",
    "Now we get to the good stuff. We have the data, what now?\n",
    "As we saw earlier, the lib script `plotEpicsData.py` provides us with classes that handle all the plotting infrastucture. It also provides a set of functions to manipulate the data to our hearts content. For more examples, checkout `examples/` where you can find example scripts that use this library.\n",
    "To illustrate how we can go about using this awesome set of tools, let's go through an example exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea91a51-9d48-43dc-ab9c-fb4dc5f653c5",
   "metadata": {},
   "source": [
    "### Fault Report FR-42809\n",
    "For this example we will be analizing data related to __[FR-42809](https://osc.cl.gemini.edu/browse/FR-42809)__. Run the cells in the following sections to obtain a set of graphs that will help identify what happened during the FR's event.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning!:</b> If you don't have access to the data file used in the example, please uncomment and run the cell below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c02c3-fd7f-4726-b7cb-ffca461586d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!../util/inPosDataCap.py gea gs ../examples/FR42809-chans.txt 230417T2200 230418T0200 -cn FT-OpsNight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07644d-ff31-499d-bf4c-b49db680be06",
   "metadata": {},
   "source": [
    "#### Modules\n",
    "The first step is to import the necessary tools from `plotEpicsData.py`. The stuff to import is explained as follows\n",
    " - `DataAx`: This is the class that defines an individual plot. This means defining the axis box characteristics as well as the data visualization properties.\n",
    " - `DataAxePlotter`: This is the class that defines the grid and handles the relative size and position for a group of axis.\n",
    "\n",
    "These classes are imported individually, since they could be used in several places throughout the script, dependindg in the number of plots involved. We also import `plotEpicsData` as a whole module in order to use the different functions defined in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab800e4b-ec2f-4b3c-a3a0-cf94ae876d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following line is needed for interactive plotting embedded in the notebook\n",
    "%matplotlib ipympl\n",
    "\n",
    "# Load the necessary modules\n",
    "from chanmonitor.lib.plotEpicsData import DataAx, DataAxePlotter\n",
    "import chanmonitor.lib.plotEpicsData as ped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9eb26-5b52-4c56-837e-e871329c4508",
   "metadata": {},
   "source": [
    "#### The data\n",
    "In the first section of the script, we define the following\n",
    " - The **name of the file** that holds the data\n",
    " - The **location** of said file\n",
    " - The **start and end times** that define the span of the plot\n",
    " \n",
    "In this case, we will be looking at `FT-OpsNight-230417T2200.h5`, a file with data gathered from the Operations Night on April 17th, 2023 using the utility described in the first section. We won't define a time window explicitly, which means we'll plot the entire time range contained in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba23e2-ff01-45ad-b6a8-87ed883ff287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = 'FT-OpsNight-230417T2200.h5'\n",
    "file_loc = '../data/'\n",
    "hdf5File = file_loc + file_name\n",
    "stime = ''\n",
    "etime = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560d1bb-7922-4805-8387-9e38b728e808",
   "metadata": {},
   "source": [
    "The data is extracted from the file using `extract_hdf5`. This function generates a python dictionary containing the data from all the records contained in the hdf5 file. In this case, the dictionary generated is stored in `recData`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70af77-bcb8-47a6-bde8-b1ba8ebeb482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read h5 file\n",
    "recData = ped.extract_hdf5([hdf5File],\n",
    "                           stime,\n",
    "                           etime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab72e26-5471-484f-8d81-651828ba403a",
   "metadata": {},
   "source": [
    "#### Data manipulation and analysis\n",
    "Once we have the dictionary, we can start playing with the data. For this example we will be doing the following processing:\n",
    " - **Extract demands from demand arrays**: Pretty self explanatory\n",
    " - **Missing demands analysis**: We want to know if any of the demands generated by the TCS where lost during transmission to the MCS. For this we'll use a function that finds any demands present at the TCS but missing in the MCS. We'll also calculate statistics to include as info in our plots. Finally well generate an array that bins the number of lost demands over a set time differential (bin window)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798984c-37fb-4ea6-a86b-f8c462908f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract demands from TCS demands array\n",
    "tcs_dmd_val = [d[13] for d in recData['tcs:drives:driveMCS.VALI'][1]]\n",
    "tcs_dmd_array = [recData['tcs:drives:driveMCS.VALI'][0], tcs_dmd_val]\n",
    "# Extract demands at end point array in MCS\n",
    "mcs_fllw_val = [d[3] for d in recData['mc:followA.J'][1]]\n",
    "mcs_fllw_array = [recData['mc:followA.J'][0], mcs_fllw_val]\n",
    "\n",
    "# Find missing demands\n",
    "tcs_lost = ped.lost_dmd(recData['tcs:drives:driveMCS.VALI'],\n",
    "                        recData['mc:followA.J'])\n",
    "# Calculate lost demands statistics\n",
    "tcs_total = len(recData['tcs:drives:driveMCS.VALI'][0])\n",
    "tcs_total_lost = len(tcs_lost[0])\n",
    "lost_prcnt = (tcs_total_lost/tcs_total) * 100\n",
    "tcs_total_accum = [tcs_lost[0], list(range(1,tcs_total_lost+1))]\n",
    "\n",
    "# Distribute lost demands over bins of diff_window span\n",
    "diff_window = 1\n",
    "lost_pkg_diff = ped.lost_dmd_diff(tcs_lost, diff_min=diff_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe66ef4-04f0-4698-8fde-75d9206d9555",
   "metadata": {},
   "source": [
    "#### Configuring plots\n",
    "With the data manipulation out of the way, is time to care of data viz. For this example, we'll plot the following:\n",
    " - **Azimuth**: Demand, Demand at Tx, Demand at Rx, Current Position, Position error, Error reported by the PMAC\n",
    " - **Lost demands**: scatter plot of lost demands over time, binned plot of lost demands over time in bins of 1 min.\n",
    "\n",
    "Each plot is configured using the `DataAx` class. With this class we can define many attributes. For this example, we'll be configuring attributes such as:\n",
    " - Line and marker color, eg. __[xkcd colors](https://xkcd.com/color/rgb/)__\n",
    " - Line width\n",
    " - Marker size\n",
    " - Marker type\n",
    " - Axis label\n",
    " - Plot label\n",
    " - Box height\n",
    " \n",
    "Special mention to **box height**. If this parameter is not specified, **all boxes have the same height**. When this parameter is set for a plot, **all unspecified boxes get a height of 1 with the specific height being a multiplyer of said unit height**. This description can be confusing, but all that matters is that **plots will always fill up the entire column in which they are plotted**. The example plot should clarify this further.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Go nuts:</b> Feel free to play by changing each attribute and see how the plot changes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331458c5-9b81-4514-8607-add70f77b442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mc_azDmd = DataAx(recData['mc:azDemandPos'],\n",
    "                  'xkcd:grass green',\n",
    "                  label='mc:azDemandPos',\n",
    "                  ylabel='Position [deg]',\n",
    "                  marker='o',\n",
    "                  marksize=5,\n",
    "                  zone=zones_dict,\n",
    "                  linewidth=1.5)\n",
    "\n",
    "mc_azPos = DataAx(recData['mc:azCurrentPos'],\n",
    "                  'xkcd:bright blue',\n",
    "                  label='mc:azCurrentPos',\n",
    "                  ylabel='Position [deg]',\n",
    "                  marker='o',\n",
    "                  marksize=5,\n",
    "                  linewidth=1.25)\n",
    "\n",
    "mc_azPos_tcs = DataAx(tcs_dmd_array,\n",
    "                      'xkcd:hot pink',\n",
    "                      label='tcs:drives:driveMCS.VALI',\n",
    "                      ylabel='Position [deg]',\n",
    "                      marker='o',\n",
    "                      marksize=5,\n",
    "                      linewidth=1.25)\n",
    "\n",
    "mc_azPos_fllw = DataAx(mcs_fllw_array,\n",
    "                       'xkcd:neon blue',\n",
    "                       label='mc:followA.J',\n",
    "                       ylabel='Position [deg]',\n",
    "                       marker='o',\n",
    "                       marksize=5,\n",
    "                       linewidth=1.25)\n",
    "\n",
    "mc_azPos_tcs = DataAx(tcs_dmd_array,\n",
    "                      'xkcd:hot pink',\n",
    "                      label='tcs:drives:driveMCS.VALI',\n",
    "                      ylabel='Position [deg]',\n",
    "                      marker='o',\n",
    "                      marksize=5,\n",
    "                      linewidth=1.25)\n",
    "\n",
    "mc_azPos_fllw = DataAx(mcs_fllw_array,\n",
    "                       'xkcd:neon blue',\n",
    "                       label='mc:followA.J',\n",
    "                       ylabel='Position [deg]',\n",
    "                       marker='o',\n",
    "                       marksize=5,\n",
    "                       linewidth=1.25)\n",
    "\n",
    "mc_azErr = DataAx([recData['mc:azPosError'][0],\n",
    "                   recData['mc:azPosError'][1]],\n",
    "                  'xkcd:brick red',\n",
    "                  label='mc:azPosError',\n",
    "                  ylabel='Position Error [deg]',\n",
    "                  ylims = ylim_dr_mcs,\n",
    "                  height = 2,\n",
    "                  linewidth=1.25)\n",
    "\n",
    "mc_azPmacErr = DataAx(recData['mc:azPmacPosError'],\n",
    "                      'xkcd:plum',\n",
    "                      label='mc:azPmacPosError',\n",
    "                      ylabel='Position Error [deg]',\n",
    "                      ylims = ylim_dr_mcs,\n",
    "                      height = 2,\n",
    "                      linewidth=1.25)\n",
    "\n",
    "tcs_lost_dmd = DataAx(tcs_lost,\n",
    "                      'xkcd:cherry',\n",
    "                      linestyle='',\n",
    "                      marker='o',\n",
    "                      label=f'Lost Dmd: {lost_prcnt:.2f}% {tcs_total_lost}/{tcs_total}',\n",
    "                      ylabel='Lost Pkg [bool]')\n",
    "\n",
    "tcs_lost_diff = DataAx(lost_pkg_diff,\n",
    "                       'xkcd:cherry',\n",
    "                       marker='o',\n",
    "                       height = 2,\n",
    "                       drawstyle='steps-post',\n",
    "                       label=f'Acc Lost Dmd, Diff={diff_window} [min] ',\n",
    "                       ylabel=f'Acc Lost Pkg [count]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12610491-6ed9-4085-8e1a-c17b637da182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plts = DataAxePlotter(ncols=1)\n",
    "\n",
    "plts.Axe['c1']['mc_azPos'] = mc_azPos\n",
    "#plts.Axe['c2']['mc_azDmd'] = mc_azDmd\n",
    "#plts.Axe['c2']['mc_azPos'] = DataAx.update_axe(mc_azPos,\n",
    "#                                                   shaxname='mc_azDmd')\n",
    "#plts.Axe['c2']['mc_azPos_tcs'] = DataAx.update_axe(mc_azPos_tcs,\n",
    "#                                                   shaxname='mc_azDmd')\n",
    "#plts.Axe['c2']['mc_azPos_fllw'] = DataAx.update_axe(mc_azPos_fllw,\n",
    "#                                                   shaxname='mc_azDmd')\n",
    "# plts.Axe['c1']['mc_azPmacDmd'] = mc_azPmacDmd\n",
    "#plts.Axe['c1']['mc_azErr'] = mc_azErr\n",
    "#plts.Axe['c1']['mc_azPmacErr'] = mc_azPmacErr\n",
    "#plts.Axe['c1']['tcs_lost_dmd'] = tcs_lost_dmd\n",
    "#plts.Axe['c1']['tcs_lost_diff'] = tcs_lost_diff\n",
    "\n",
    "# plts.Axe['c2']['mc_elDmd'] = mc_elDmd\n",
    "# plts.Axe['c2']['mc_elPos'] = DataAx.update_axe(mc_elPos,\n",
    "                                                   # shaxname='mc_elDmd')\n",
    "# plts.Axe['c2']['mc_elPmacDmd'] = mc_elPmacDmd\n",
    "# plts.Axe['c2']['mc_elErr'] = mc_elErr\n",
    "# plts.Axe['c2']['mc_elPmacErr'] = mc_elPmacErr\n",
    "\n",
    "# plts.Axe['c3']['mc_trk_azerr_fft'] = mc_trk_azerr_fft\n",
    "# plts.Axe['c3']['mc_trk_elerr_fft'] = mc_trk_elerr_fft\n",
    "plts.positionPlot()\n",
    "plts.plotConfig('FR-42809 Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a89e83-3b16-4cdd-9cd0-9c019d3662f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
